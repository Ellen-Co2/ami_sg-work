#treat trainfrom pandas import DataFrame, Seriesimport numpy as npimport pandas as pdfrom datetime import datetime, timedeltaimport sqlite3from sqlalchemy import create_engineconn = sqlite3.connect('new.sqlite')disk_engine = create_engine('sqlite:///new.sqlite')print "start read sql.."begi = datetime.now()'''All =  pd.read_sql_query('SELECT mac,bldid, sgtime,interval,status FROM wifi LIMIT 10',disk_engine)unkn = pd.read_sql_query('SELECT mac,bldid, sgtime FROM wifi WHERE status = "UNKNOWN"',disk_engine)#ass = pd.read_sql_query('SELECT mac,bldid, sgtime FROM wifi WHERE status = "ASSOCIATED" ',disk_engine)#lost = pd.read_sql_query('SELECT mac FROM lost',disk_engine).mac.unique()poin1 = datetime.now()t1 = timedelta.total_seconds(poin1 - begi)print "spend %s reading " %t1All["sgtime"] = pd.to_datetime(All['sgtime'])start = All.iloc[0,2]print "start make time group in 20 mins interval...fill the lost entries' interval nan"interv = []tt = []for i,row in enumerate(All.values):    #if i <= 10:    t = int(timedelta.total_seconds(All.sgtime[i]-start)/1200)        #print t    #else: break    if All.mac[i] in lost:        temp = np.nan    else:        temp = All.interval[i]    interv.append(temp)    tt.append(t)print "dims of t_grp: ",len(tt)poin2 = datetime.now()print "spend %s make t_grp " %timedelta.total_seconds(poin2 - poin1)All["interv"] = intervAll["t_grp"] = tt#sta = pd.get_dummies(All['statustype'])#All = pd.concat([All,sta],axis=1)print "now dimension is : " , All.shapeprint "columns are: " , All.columnsdef sta_num(df):    df["sgtime"] = pd.to_datetime(df["sgtime"])    tt = []    for i,row in enumerate(df.values):        #if i <= 10:        t = int(timedelta.total_seconds(df.sgtime[i]-start)/1200)            #print t        #else: break        tt.append(t)        #print tt    df["t_grp"] = tt    sta_agg = {"sgtime": 'min',"mac": lambda x: len(x.unique())}    df_agg = df.groupby(["bldid","t_grp"]).agg(sta_agg)    return df_agg#sta_num(prob).to_csv("prob_agg.csv",index = True)#sta_num(ass).to_csv("ass_agg.csv", index = True)sta_num(unkn).to_csv("unknown_agg.csv",index = True)'''pre_tr = pd.read_csv('/Users/AAA218/Desktop/ami_sg/all_agg.csv',header = 0, sep =",",low_memory=False)print "new columns after agg are: ", pre_tr.columnsprint " sample entries: \n", pre_tr.head()unk_new = pd.read_csv('/Users/AAA218/Desktop/ami_sg/unknown_agg.csv',header = 0, sep =",",low_memory=False)ass_new = pd.read_csv('/Users/AAA218/Desktop/ami_sg/ass_agg.csv',header = 0, sep =",",low_memory=False)unk_new.rename(columns = {'mac':'UNKNOWN'},inplace = True)unk_new.drop("sgtime", axis = 1, inplace = True)ass_new.drop("sgtime", axis = 1, inplace = True)ass_new.rename(columns = {'mac':'ASSOCIATED'},inplace = True)print "unknown to merge: \n", unk_new.head()print "associated to merge: \n", ass_new.head()print "start to join...."def comb(df1,df2):    df = pd.merge(df1,df2, how = "left", on = ['bldid','t_grp'])    print "null cases: \n", df.isnull().sum()    for col in df2.columns:        if col not in df1.columns:            #print col            df[col].fillna(0, inplace = True)    print "null check: \n", df.isnull().sum()    return dfa = comb(pre_tr, unk_new)a1 = comb(a, ass_new)a1["PROBING"] = a1["mac"]- a1["UNKNOWN"] - a1["ASSOCIATED"]print "---------sample:----------\n",a1.head()'''               mac              sgtimebldid   t_grp                         SDE1-02 0        1 2016-04-16 00:00:01        8        1 2016-04-16 02:40:01        23       1 2016-04-16 07:50:01        28       1 2016-04-16 09:35:02        29       1 2016-04-16 09:40:01''''''print "start aggregation....."aggre = {"sgtime": 'min', "mac": lambda x: len(x.unique()),"interv":'median' }All_ans = All.groupby(["bldid","t_grp"]).agg(aggre)All_ans.to_csv('all_agg.csv',index= True)'''hr = []mins = []weeks = []for i, row in enumerate(a1.values):    #if i >5 : break    tt = datetime.strptime(a1.sgtime[i], "%Y-%m-%d %H:%M:%S")    h = tt.hour    m = tt.minute    wk = tt.strftime("%w") #0-6    #print "hour:%s, minute: %s, day: %s " %(h ,m ,wk)    hr.append(h)    mins.append(m)    weeks.append(wk)temp = DataFrame({"hr":hr,"mins":mins,"wks":weeks})tr = pd.concat([a1,temp],axis=1)tr.rename(columns = {'mac':'device_num'},inplace = True)## make dummies for buildings#bldcode = pd.get_dummies(tr['bldid'])#tr = pd.concat([tr,bldcode],axis=1)#tr.drop("sgtime",axis = 1, inplace = True)print "final columns:\n ", tr.head()print "final dims: ",tr.shapetr.to_csv('tr_20min_named.csv',index = False)